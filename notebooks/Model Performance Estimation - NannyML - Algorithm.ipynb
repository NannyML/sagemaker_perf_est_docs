{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Using NannyML Performance Estimation Algorithm from AWS Marketplace "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Overview\n",
    "\n",
    "NannyML can estimate the performance of a machine learning model running in production. You can read more about how it works [here](https://nannyml.readthedocs.io/en/stable/how_it_works/performance_estimation.html).\n",
    "\n",
    "\n",
    "This sample notebook shows you how to use [Model Performance Estimation - NannyML](https://aws.amazon.com/marketplace/pp/prodview-uotyt66szg34o) from AWS Marketplace to estimate the performance of your deployed machine learnign models.\n",
    "\n",
    "Performance Estimation can work for binary classification, multiclass classification and regression.\n",
    "\n",
    "> **Note**: This is a reference notebook and it cannot run unless you make changes suggested in the notebook.\n",
    "\n",
    "## Pre-requisites\n",
    "1. **Note**: This notebook contains elements which render correctly in Jupyter interface. Open this notebook from an Amazon SageMaker Notebook Instance or Amazon SageMaker Studio.\n",
    "1. Ensure that IAM role used has **AmazonSageMakerFullAccess**\n",
    "1. Some hands-on experience using [Amazon SageMaker](https://aws.amazon.com/sagemaker/).\n",
    "1. To use this algorithm successfully, ensure that:\n",
    "    1. Either your IAM role has these three permissions and you have authority to make AWS Marketplace subscriptions in the AWS account used: \n",
    "        1. **aws-marketplace:ViewSubscriptions**\n",
    "        1. **aws-marketplace:Unsubscribe**\n",
    "        1. **aws-marketplace:Subscribe**  \n",
    "    2. or your AWS account has a subscription to [Model Performance Estimation - NannyML](https://aws.amazon.com/marketplace/pp/prodview-uotyt66szg34o). \n",
    "\n",
    "## Contents\n",
    "1. [Subscribe to the algorithm](#1.-Subscribe-to-the-algorithm)\n",
    "1. [Prepare dataset](#2.-Prepare-dataset)\n",
    "\t1. [Dataset format expected by the algorithm](#A.-Dataset-format-expected-by-the-algorithm)\n",
    "\t1. [Configure and visualize reference dataset](#B.-Configure-and-visualize-reference-dataset)\n",
    "\t1. [Upload datasets to Amazon S3](#C.-Upload-datasets-to-Amazon-S3)\n",
    "1. [Train the machine learning algorithm](#3:-Train-the-machine-learning-algorithm)\n",
    "\t1. [Set up environment](#3.1-Set-up-environment)\n",
    "\t1. [Train a model](#3.2-Train-the-algorithm)\n",
    "1. [Deploy model](#4:-Deploy-model)\n",
    "1. [Perform Batch Inference](#5.-Perform-Batch-Inference)\n",
    "1. [Clean-up](#6.-Clean-up)\n",
    "\t1. [Delete the model](#A.-Delete-the-model)\n",
    "\t1. [Unsubscribe to the listing (optional)](#B.-Unsubscribe-to-the-listing-(optional))\n",
    "\n",
    "\n",
    "## Usage instructions\n",
    "You can run this notebook one cell at a time (By using Shift+Enter for running a cell)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Subscribe to the algorithm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To subscribe to the algorithm:\n",
    "1. Open the algorithm listing page [Model Performance Estimation - NannyML](https://aws.amazon.com/marketplace/pp/prodview-uotyt66szg34o)\n",
    "1. On the AWS Marketplace listing,  click on **Continue to subscribe** button.\n",
    "1. On the **Subscribe to this software** page, review and click on **\"Accept Offer\"** if you agree with EULA, pricing, and support terms. \n",
    "1. Once you click on **Continue to configuration button** and then choose a **region**, you will see a **Product Arn**. This is the algorithm ARN that you need to specify while training a custom ML model. Copy the ARN corresponding to your region and specify the same in the following cell.\n",
    "\n",
    "<font color='red'>Directly copy your assigned ARN code below:<font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "algo_arn = \"<Customer to specify algorithm ARN corresponding to their AWS region>\"\n",
    "# Internally used arn.txt to specify arn to run the notebook\n",
    "# with open('arn.txt', 'r') as file:\n",
    "#     algo_arn = file.read().rstrip()\n",
    "\n",
    "# Show specified ARN\n",
    "# algo_arn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Prepare dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import sagemaker as sage\n",
    "from sagemaker import get_execution_role\n",
    "import pandas as pd\n",
    "import json"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### A. Dataset format expected by the algorithm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To fully demonstrate the capabilities of NannyML's performance estimation we will provide code for all 3 supported machine learning problem types.\n",
    "\n",
    "- For Binary Classification we are going to use [NannyML's synthetic car loan dataset](https://nannyml.readthedocs.io/en/stable/datasets/binary_car_loan.html).\n",
    "- For Multiclass Classification we are going to use [NannyML's synthetic multiclass creadit card assignment dataset](https://nannyml.readthedocs.io/en/stable/datasets/multiclass.html).\n",
    "- For Regression we are going to use [NannyML's synthetic car price dataset](https://nannyml.readthedocs.io/en/stable/datasets/regression.html).\n",
    "\n",
    "\n",
    "You can find some information about dataset format in **Usage Information** section of [Model Performance Estimation - NannyML](https://aws.amazon.com/marketplace/pp/prodview-uotyt66szg34o).\n",
    "<br>\n",
    "More detailed information can be found in [NannyML's Data Requirements Documentation](https://nannyml.readthedocs.io/en/stable/tutorials/data_requirements.html).\n",
    "\n",
    "<font color='red'>Edit code below as appropriate for the Machine Learning problem type you are interested in:<font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# machine_learning_problem_type = \"Binary Classification\"\n",
    "machine_learning_problem_type = \"Multiclass Classification\"\n",
    "# machine_learning_problem_type = \"Regression\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### B. Configure and visualize reference dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>acq_channel</th>\n",
       "      <th>app_behavioral_score</th>\n",
       "      <th>requested_credit_limit</th>\n",
       "      <th>app_channel</th>\n",
       "      <th>credit_bureau_score</th>\n",
       "      <th>stated_income</th>\n",
       "      <th>is_customer</th>\n",
       "      <th>timestamp</th>\n",
       "      <th>y_pred_proba_prepaid_card</th>\n",
       "      <th>y_pred_proba_highstreet_card</th>\n",
       "      <th>y_pred_proba_upmarket_card</th>\n",
       "      <th>y_pred</th>\n",
       "      <th>y_true</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Partner3</td>\n",
       "      <td>1.808232</td>\n",
       "      <td>350</td>\n",
       "      <td>web</td>\n",
       "      <td>309</td>\n",
       "      <td>15000</td>\n",
       "      <td>True</td>\n",
       "      <td>2020-05-02 02:01:30</td>\n",
       "      <td>0.97</td>\n",
       "      <td>0.03</td>\n",
       "      <td>0.00</td>\n",
       "      <td>prepaid_card</td>\n",
       "      <td>prepaid_card</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Partner2</td>\n",
       "      <td>4.382568</td>\n",
       "      <td>500</td>\n",
       "      <td>mobile</td>\n",
       "      <td>418</td>\n",
       "      <td>23000</td>\n",
       "      <td>True</td>\n",
       "      <td>2020-05-02 02:03:33</td>\n",
       "      <td>0.87</td>\n",
       "      <td>0.13</td>\n",
       "      <td>0.00</td>\n",
       "      <td>prepaid_card</td>\n",
       "      <td>prepaid_card</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Partner2</td>\n",
       "      <td>-0.787575</td>\n",
       "      <td>400</td>\n",
       "      <td>web</td>\n",
       "      <td>507</td>\n",
       "      <td>24000</td>\n",
       "      <td>False</td>\n",
       "      <td>2020-05-02 02:04:49</td>\n",
       "      <td>0.47</td>\n",
       "      <td>0.35</td>\n",
       "      <td>0.18</td>\n",
       "      <td>prepaid_card</td>\n",
       "      <td>upmarket_card</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Partner3</td>\n",
       "      <td>-2.131770</td>\n",
       "      <td>300</td>\n",
       "      <td>mobile</td>\n",
       "      <td>324</td>\n",
       "      <td>38000</td>\n",
       "      <td>False</td>\n",
       "      <td>2020-05-02 02:07:59</td>\n",
       "      <td>0.26</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.24</td>\n",
       "      <td>highstreet_card</td>\n",
       "      <td>upmarket_card</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Partner3</td>\n",
       "      <td>-1.362938</td>\n",
       "      <td>450</td>\n",
       "      <td>mobile</td>\n",
       "      <td>736</td>\n",
       "      <td>38000</td>\n",
       "      <td>True</td>\n",
       "      <td>2020-05-02 02:20:19</td>\n",
       "      <td>0.03</td>\n",
       "      <td>0.04</td>\n",
       "      <td>0.93</td>\n",
       "      <td>upmarket_card</td>\n",
       "      <td>upmarket_card</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  acq_channel  app_behavioral_score  requested_credit_limit app_channel   \n",
       "0    Partner3              1.808232                     350         web  \\\n",
       "1    Partner2              4.382568                     500      mobile   \n",
       "2    Partner2             -0.787575                     400         web   \n",
       "3    Partner3             -2.131770                     300      mobile   \n",
       "4    Partner3             -1.362938                     450      mobile   \n",
       "\n",
       "   credit_bureau_score  stated_income  is_customer            timestamp   \n",
       "0                  309          15000         True  2020-05-02 02:01:30  \\\n",
       "1                  418          23000         True  2020-05-02 02:03:33   \n",
       "2                  507          24000        False  2020-05-02 02:04:49   \n",
       "3                  324          38000        False  2020-05-02 02:07:59   \n",
       "4                  736          38000         True  2020-05-02 02:20:19   \n",
       "\n",
       "   y_pred_proba_prepaid_card  y_pred_proba_highstreet_card   \n",
       "0                       0.97                          0.03  \\\n",
       "1                       0.87                          0.13   \n",
       "2                       0.47                          0.35   \n",
       "3                       0.26                          0.50   \n",
       "4                       0.03                          0.04   \n",
       "\n",
       "   y_pred_proba_upmarket_card           y_pred         y_true  \n",
       "0                        0.00     prepaid_card   prepaid_card  \n",
       "1                        0.00     prepaid_card   prepaid_card  \n",
       "2                        0.18     prepaid_card  upmarket_card  \n",
       "3                        0.24  highstreet_card  upmarket_card  \n",
       "4                        0.93    upmarket_card  upmarket_card  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "if machine_learning_problem_type == \"Binary Classification\":\n",
    "    reference_dataset = \"data/bc_reference.csv\"\n",
    "elif machine_learning_problem_type == \"Multiclass Classification\":\n",
    "    reference_dataset = \"data/mc_reference.csv\"\n",
    "elif machine_learning_problem_type == \"Regression\":\n",
    "    reference_dataset = \"data/reg_reference.csv\"\n",
    "else:\n",
    "    raise ValueError(\"Unsupported Machine Learning Problem Type.\")\n",
    "\n",
    "# Show selected dataset\n",
    "pd.read_csv(reference_dataset).head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### C. Upload datasets to Amazon S3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "sagemaker_session = sage.Session()\n",
    "bucket = sagemaker_session.default_bucket()\n",
    "# Uncomment below to see selected default bucket\n",
    "# bucket"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "demo_prefix = \"doc-notebook-demo\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "reference_data = sagemaker_session.upload_data(\n",
    "    reference_dataset, bucket=bucket, key_prefix=demo_prefix\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3: Train the machine learning algorithm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that dataset is available in an accessible Amazon S3 bucket, we are ready to train a machine learning model. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1 Set up environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "role = get_execution_role()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "output_location = f\"s3://{bucket}/{demo_prefix}/output\"\n",
    "# Uncomment below to see specified output location for Algorithm artifacts and outputs\n",
    "# output_location"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2 Train the algorithm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can also find more information about dataset format in **Hyperparameters** section of [Model Performance Estimation - NannyML](https://aws.amazon.com/marketplace/pp/prodview-uotyt66szg34o).\n",
    "\n",
    "For even more detailed information you read NannyML tutorials on performance estimation for:\n",
    "- [Binary Classification](https://nannyml.readthedocs.io/en/stable/tutorials/performance_estimation/binary_performance_estimation.html)\n",
    "- [Multiclass Classification](https://nannyml.readthedocs.io/en/stable/tutorials/performance_estimation/multiclass_performance_estimation.html)\n",
    "- [Regression](https://nannyml.readthedocs.io/en/stable/tutorials/performance_estimation/regression_performance_estimation.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Define hyperparameters\n",
    "if machine_learning_problem_type == \"Binary Classification\":\n",
    "    nannyml_parameters = {\n",
    "        \"y_pred_proba\": \"y_pred_proba\",\n",
    "        \"y_pred\": \"y_pred\",\n",
    "        \"y_true\": \"repaid\",\n",
    "        \"timestamp_column_name\": \"timestamp\",\n",
    "        \"metrics\": [\"roc_auc\"],\n",
    "        \"chunk_size\": 5000,\n",
    "        \"problem_type\": \"classification_binary\",\n",
    "    }\n",
    "    # json.dumps needed due to sagemaker specifications\n",
    "    sagemaker_hyperparameters = {\n",
    "        \"data_filename\": reference_dataset.split(\"/\")[-1],\n",
    "        \"data_type\": \"csv\",\n",
    "        \"problem_type\": \"classification_binary\",\n",
    "        \"parameters\": json.dumps(nannyml_parameters),\n",
    "    }\n",
    "elif machine_learning_problem_type == \"Multiclass Classification\":\n",
    "    nannyml_parameters = {\n",
    "        \"y_pred\": \"y_pred\",\n",
    "        \"y_pred_proba\": {\n",
    "            \"prepaid_card\": \"y_pred_proba_prepaid_card\",\n",
    "            \"highstreet_card\": \"y_pred_proba_highstreet_card\",\n",
    "            \"upmarket_card\": \"y_pred_proba_upmarket_card\"\n",
    "        },\n",
    "        \"y_true\": \"y_true\",\n",
    "        \"timestamp_column_name\": \"timestamp\",\n",
    "        \"metrics\": [\"roc_auc\"],\n",
    "        \"chunk_size\": 5000,\n",
    "        \"problem_type\": \"classification_multiclass\",\n",
    "    }\n",
    "    # json.dumps needed due to sagemaker specifications\n",
    "    sagemaker_hyperparameters = {\n",
    "        \"data_filename\": \"mc_reference.csv\",\n",
    "        \"data_type\": \"csv\",\n",
    "        \"problem_type\": \"classification_multiclass\",\n",
    "        \"parameters\": json.dumps(nannyml_parameters),\n",
    "    }\n",
    "elif machine_learning_problem_type == \"Regression\":\n",
    "    nannyml_parameters = {\n",
    "        \"feature_column_names\": [\n",
    "            \"car_age\",\n",
    "            \"km_driven\",\n",
    "            \"price_new\",\n",
    "            \"accident_count\",\n",
    "            \"door_count\",\n",
    "            \"fuel\",\n",
    "            \"transmission\",\n",
    "        ],\n",
    "        \"y_pred\": \"y_pred\",\n",
    "        \"y_true\": \"y_true\",\n",
    "        \"timestamp_column_name\": \"timestamp\",\n",
    "        \"metrics\": [\"rmse\"],\n",
    "        \"chunk_size\": 6000,\n",
    "        \"tune_hyperparameters\": False,\n",
    "    }\n",
    "    # json.dumps needed due to sagemaker specifications\n",
    "    sagemaker_hyperparameters = {\n",
    "        \"data_filename\": reference_dataset.split(\"/\")[-1],\n",
    "        \"data_type\": \"csv\",\n",
    "        \"problem_type\": \"regression\",\n",
    "        \"parameters\": json.dumps(nannyml_parameters),\n",
    "    }\n",
    "else:\n",
    "    raise ValueError(\"Unsupported Machine Learning Problem Type.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For information on creating an `Estimator` object, see [documentation](https://sagemaker.readthedocs.io/en/stable/api/training/estimators.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Create an estimator object for running a training job\n",
    "estimator = sage.algorithm.AlgorithmEstimator(\n",
    "    algorithm_arn=algo_arn,\n",
    "    base_job_name='nml-perf-est',\n",
    "    role=role,\n",
    "    instance_count=1,\n",
    "    instance_type='ml.m5.large',\n",
    "    input_mode=\"File\",\n",
    "    output_path=output_location,\n",
    "    sagemaker_session=sagemaker_session,\n",
    "    hyperparameters=sagemaker_hyperparameters,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:sagemaker:Creating training-job with name: nml-perf-est-2023-08-21-06-17-54-258\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-08-21 06:17:54 Starting - Starting the training job...\n",
      "2023-08-21 06:18:10 Starting - Preparing the instances for training......\n",
      "2023-08-21 06:19:04 Downloading - Downloading input data...\n",
      "2023-08-21 06:19:29 Training - Downloading the training image...\n",
      "2023-08-21 06:20:20 Uploading - Uploading generated training model\u001b[34mINFO:nannyml:Logger object created.\u001b[0m\n",
      "\u001b[34mINFO:nannyml:Hyperparameters read.\u001b[0m\n",
      "\u001b[34mINFO:nannyml:Estimator Instantiated.\u001b[0m\n",
      "\u001b[34mINFO:nannyml:Loaded data.\u001b[0m\n",
      "\u001b[34mINFO:nannyml.base:fitting nannyml.performance_estimation.confidence_based.cbpe.CBPE\u001b[0m\n",
      "\u001b[34mDEBUG:nannyml.usage_logging:found NML_DISABLE_USAGE_LOGGING key in environment variables. Usage event CBPE estimator run not logged.\u001b[0m\n",
      "\u001b[34mDEBUG:nannyml.usage_logging:found NML_DISABLE_USAGE_LOGGING key in environment variables. Usage event CBPE estimator fit not logged.\u001b[0m\n",
      "\u001b[34mINFO:nannyml:Estimator fit.\u001b[0m\n",
      "\u001b[34mINFO:nannyml.io.store.base:storing object \"nannyml.performance_estimation.confidence_based.cbpe.CBPE\" to store \"nannyml.io.store.file_store.FilesystemStore\"\u001b[0m\n",
      "\u001b[34mDEBUG:fsspec.local:open file: /opt/ml/model/estimator.pkl\u001b[0m\n",
      "\u001b[34mDEBUG:nannyml.io.store.serializers:serializing object nannyml.performance_estimation.confidence_based.cbpe.CBPE\u001b[0m\n",
      "\u001b[34mINFO:nannyml:Estimator Stored!\u001b[0m\n",
      "\n",
      "2023-08-21 06:20:30 Completed - Training job completed\n",
      "Training seconds: 87\n",
      "Billable seconds: 87\n"
     ]
    }
   ],
   "source": [
    "# Run the training job.\n",
    "estimator.fit(\n",
    "    {'training': reference_data}\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "See this [blog-post](https://aws.amazon.com/blogs/machine-learning/easily-monitor-and-visualize-metrics-while-training-models-on-amazon-sagemaker/) for more information how to visualize metrics during the process. You can also open the training job from [Amazon SageMaker console](https://console.aws.amazon.com/sagemaker/home?#/jobs/) and monitor the metrics/logs in **Monitor** section."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4: Deploy model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**NannyML's Performance Estimation is not designed for real time inference, therefore it is not recommended to use it in this way.**\n",
    "\n",
    "For this reason we are not showcasing the real-time inference feature of Sagemaker Algorithm."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Perform Batch Inference"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this section, you will perform batch inference using multiple input payloads together."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# upload the batch-transform job input files to S3\n",
    "\n",
    "if machine_learning_problem_type == \"Binary Classification\":\n",
    "    inference_dataset = \"data/bc_analysis.csv\"\n",
    "elif machine_learning_problem_type == \"Multiclass Classification\":\n",
    "    inference_dataset = \"data/mc_analysis.csv\"\n",
    "elif machine_learning_problem_type == \"Regression\":\n",
    "    inference_dataset = \"data/reg_analysis.csv\"\n",
    "else:\n",
    "    raise ValueError(\"Unsupported Machine Learning Problem Type.\")\n",
    "\n",
    "inference_data = sagemaker_session.upload_data(inference_dataset, bucket=bucket, key_prefix=demo_prefix)\n",
    "# print(\"Transform input uploaded to \" + inference_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:sagemaker:Creating model package with name: nannyml-performance-estimation-1350cd6b-2023-08-21-06-21-07-290\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "........."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:sagemaker:Creating model with name: nannyml-performance-estimation-1350cd6b-2023-08-21-06-21-52-799\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:sagemaker:Creating transform job with name: nml-perf-est-2023-08-21-06-21-55-859\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "...........................\n",
      "\u001b[34m * Serving Flask app '/web_app_serve.py'\n",
      " * Debug mode: off\u001b[0m\n",
      "\u001b[34m#033[31m#033[1mWARNING: This is a development server. Do not use it in a production deployment. Use a production WSGI server instead.#033[0m\n",
      " * Running on all addresses (0.0.0.0)\n",
      " * Running on http://127.0.0.1:8080\n",
      " * Running on http://127.0.0.1:8080\u001b[0m\n",
      "\u001b[34m#033[33mPress CTRL+C to quit#033[0m\u001b[0m\n",
      "\u001b[34m169.254.255.130 - - [21/Aug/2023 06:26:31] \"GET /ping HTTP/1.1\" 200 -\u001b[0m\n",
      "\u001b[34m169.254.255.130 - - [21/Aug/2023 06:26:31] \"#033[33mGET /execution-parameters HTTP/1.1#033[0m\" 404 -\u001b[0m\n",
      "\u001b[34mReceived POST invocation request.\u001b[0m\n",
      "\u001b[34mEstimation invoked with 60000 rows\u001b[0m\n",
      "\u001b[34mEstimation invoked with columns: ['acq_channel', 'app_behavioral_score', 'requested_credit_limit', 'app_channel', 'credit_bureau_score', 'stated_income', 'is_customer', 'timestamp', 'y_pred_proba_prepaid_card', 'y_pred_proba_highstreet_card', 'y_pred_proba_upmarket_card', 'y_pred']\u001b[0m\n",
      "\u001b[34m169.254.255.130 - - [21/Aug/2023 06:26:32] \"POST /invocations HTTP/1.1\" 200 -\u001b[0m\n",
      "\u001b[32m2023-08-21T06:26:31.801:[sagemaker logs]: MaxConcurrentTransforms=1, MaxPayloadInMB=6, BatchStrategy=MULTI_RECORD\u001b[0m\n",
      "\u001b[34m * Serving Flask app '/web_app_serve.py'\n",
      " * Debug mode: off\u001b[0m\n",
      "\u001b[34m#033[31m#033[1mWARNING: This is a development server. Do not use it in a production deployment. Use a production WSGI server instead.#033[0m\n",
      " * Running on all addresses (0.0.0.0)\n",
      " * Running on http://127.0.0.1:8080\n",
      " * Running on http://127.0.0.1:8080\u001b[0m\n",
      "\u001b[34m#033[33mPress CTRL+C to quit#033[0m\u001b[0m\n",
      "\u001b[35m * Serving Flask app '/web_app_serve.py'\n",
      " * Debug mode: off\u001b[0m\n",
      "\u001b[35m#033[31m#033[1mWARNING: This is a development server. Do not use it in a production deployment. Use a production WSGI server instead.#033[0m\n",
      " * Running on all addresses (0.0.0.0)\n",
      " * Running on http://127.0.0.1:8080\n",
      " * Running on http://127.0.0.1:8080\u001b[0m\n",
      "\u001b[35m#033[33mPress CTRL+C to quit#033[0m\u001b[0m\n",
      "\u001b[34m169.254.255.130 - - [21/Aug/2023 06:26:31] \"GET /ping HTTP/1.1\" 200 -\u001b[0m\n",
      "\u001b[34m169.254.255.130 - - [21/Aug/2023 06:26:31] \"#033[33mGET /execution-parameters HTTP/1.1#033[0m\" 404 -\u001b[0m\n",
      "\u001b[34mReceived POST invocation request.\u001b[0m\n",
      "\u001b[35m169.254.255.130 - - [21/Aug/2023 06:26:31] \"GET /ping HTTP/1.1\" 200 -\u001b[0m\n",
      "\u001b[35m169.254.255.130 - - [21/Aug/2023 06:26:31] \"#033[33mGET /execution-parameters HTTP/1.1#033[0m\" 404 -\u001b[0m\n",
      "\u001b[35mReceived POST invocation request.\u001b[0m\n",
      "\u001b[34mEstimation invoked with 60000 rows\u001b[0m\n",
      "\u001b[35mEstimation invoked with 60000 rows\u001b[0m\n",
      "\u001b[34mEstimation invoked with columns: ['acq_channel', 'app_behavioral_score', 'requested_credit_limit', 'app_channel', 'credit_bureau_score', 'stated_income', 'is_customer', 'timestamp', 'y_pred_proba_prepaid_card', 'y_pred_proba_highstreet_card', 'y_pred_proba_upmarket_card', 'y_pred']\u001b[0m\n",
      "\u001b[34m169.254.255.130 - - [21/Aug/2023 06:26:32] \"POST /invocations HTTP/1.1\" 200 -\u001b[0m\n",
      "\u001b[35mEstimation invoked with columns: ['acq_channel', 'app_behavioral_score', 'requested_credit_limit', 'app_channel', 'credit_bureau_score', 'stated_income', 'is_customer', 'timestamp', 'y_pred_proba_prepaid_card', 'y_pred_proba_highstreet_card', 'y_pred_proba_upmarket_card', 'y_pred']\u001b[0m\n",
      "\u001b[35m169.254.255.130 - - [21/Aug/2023 06:26:32] \"POST /invocations HTTP/1.1\" 200 -\u001b[0m\n",
      "\u001b[32m2023-08-21T06:26:31.801:[sagemaker logs]: MaxConcurrentTransforms=1, MaxPayloadInMB=6, BatchStrategy=MULTI_RECORD\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "# Run the batch-transform job\n",
    "transformer = estimator.transformer(\n",
    "    instance_count=1,\n",
    "    instance_type=\"ml.m5.large\",\n",
    "    output_path=output_location\n",
    ")\n",
    "transformer.transform(inference_data, content_type=\"text/csv\")\n",
    "transformer.wait()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**View Results of Performance Estimation**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:botocore.credentials:Found credentials from IAM Role: BaseNotebookInstanceEc2InstanceRole\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th colspan=\"7\" halign=\"left\">chunk</th>\n",
       "      <th colspan=\"8\" halign=\"left\">roc_auc</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>key</th>\n",
       "      <th>chunk_index</th>\n",
       "      <th>start_index</th>\n",
       "      <th>end_index</th>\n",
       "      <th>start_date</th>\n",
       "      <th>end_date</th>\n",
       "      <th>period</th>\n",
       "      <th>value</th>\n",
       "      <th>sampling_error</th>\n",
       "      <th>realized</th>\n",
       "      <th>upper_confidence_boundary</th>\n",
       "      <th>lower_confidence_boundary</th>\n",
       "      <th>upper_threshold</th>\n",
       "      <th>lower_threshold</th>\n",
       "      <th>alert</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[0:4999]</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4999</td>\n",
       "      <td>2020-05-02 02:01:30</td>\n",
       "      <td>2020-05-12 13:12:37</td>\n",
       "      <td>reference</td>\n",
       "      <td>0.905532</td>\n",
       "      <td>0.002348</td>\n",
       "      <td>0.904142</td>\n",
       "      <td>0.912575</td>\n",
       "      <td>0.898488</td>\n",
       "      <td>0.915066</td>\n",
       "      <td>0.8993</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[5000:9999]</td>\n",
       "      <td>1</td>\n",
       "      <td>5000</td>\n",
       "      <td>9999</td>\n",
       "      <td>2020-05-12 13:14:18</td>\n",
       "      <td>2020-05-22 13:37:58</td>\n",
       "      <td>reference</td>\n",
       "      <td>0.909840</td>\n",
       "      <td>0.002348</td>\n",
       "      <td>0.907698</td>\n",
       "      <td>0.916883</td>\n",
       "      <td>0.902797</td>\n",
       "      <td>0.915066</td>\n",
       "      <td>0.8993</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[10000:14999]</td>\n",
       "      <td>2</td>\n",
       "      <td>10000</td>\n",
       "      <td>14999</td>\n",
       "      <td>2020-05-22 13:41:07</td>\n",
       "      <td>2020-06-01 18:55:46</td>\n",
       "      <td>reference</td>\n",
       "      <td>0.906800</td>\n",
       "      <td>0.002348</td>\n",
       "      <td>0.907093</td>\n",
       "      <td>0.913844</td>\n",
       "      <td>0.899757</td>\n",
       "      <td>0.915066</td>\n",
       "      <td>0.8993</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[15000:19999]</td>\n",
       "      <td>3</td>\n",
       "      <td>15000</td>\n",
       "      <td>19999</td>\n",
       "      <td>2020-06-01 18:59:40</td>\n",
       "      <td>2020-06-11 19:49:03</td>\n",
       "      <td>reference</td>\n",
       "      <td>0.906455</td>\n",
       "      <td>0.002348</td>\n",
       "      <td>0.909209</td>\n",
       "      <td>0.913498</td>\n",
       "      <td>0.899412</td>\n",
       "      <td>0.915066</td>\n",
       "      <td>0.8993</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[20000:24999]</td>\n",
       "      <td>4</td>\n",
       "      <td>20000</td>\n",
       "      <td>24999</td>\n",
       "      <td>2020-06-11 19:55:34</td>\n",
       "      <td>2020-06-21 20:51:08</td>\n",
       "      <td>reference</td>\n",
       "      <td>0.907449</td>\n",
       "      <td>0.002348</td>\n",
       "      <td>0.905651</td>\n",
       "      <td>0.914492</td>\n",
       "      <td>0.900405</td>\n",
       "      <td>0.915066</td>\n",
       "      <td>0.8993</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>[25000:29999]</td>\n",
       "      <td>5</td>\n",
       "      <td>25000</td>\n",
       "      <td>29999</td>\n",
       "      <td>2020-06-21 20:51:22</td>\n",
       "      <td>2020-07-02 01:58:05</td>\n",
       "      <td>reference</td>\n",
       "      <td>0.908353</td>\n",
       "      <td>0.002348</td>\n",
       "      <td>0.910833</td>\n",
       "      <td>0.915396</td>\n",
       "      <td>0.901310</td>\n",
       "      <td>0.915066</td>\n",
       "      <td>0.8993</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>[30000:34999]</td>\n",
       "      <td>6</td>\n",
       "      <td>30000</td>\n",
       "      <td>34999</td>\n",
       "      <td>2020-07-02 02:06:56</td>\n",
       "      <td>2020-07-12 05:34:14</td>\n",
       "      <td>reference</td>\n",
       "      <td>0.907318</td>\n",
       "      <td>0.002348</td>\n",
       "      <td>0.903115</td>\n",
       "      <td>0.914361</td>\n",
       "      <td>0.900275</td>\n",
       "      <td>0.915066</td>\n",
       "      <td>0.8993</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>[35000:39999]</td>\n",
       "      <td>7</td>\n",
       "      <td>35000</td>\n",
       "      <td>39999</td>\n",
       "      <td>2020-07-12 05:35:07</td>\n",
       "      <td>2020-07-22 12:54:57</td>\n",
       "      <td>reference</td>\n",
       "      <td>0.908308</td>\n",
       "      <td>0.002348</td>\n",
       "      <td>0.908555</td>\n",
       "      <td>0.915351</td>\n",
       "      <td>0.901265</td>\n",
       "      <td>0.915066</td>\n",
       "      <td>0.8993</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>[40000:44999]</td>\n",
       "      <td>8</td>\n",
       "      <td>40000</td>\n",
       "      <td>44999</td>\n",
       "      <td>2020-07-22 12:58:29</td>\n",
       "      <td>2020-08-01 10:14:52</td>\n",
       "      <td>reference</td>\n",
       "      <td>0.906435</td>\n",
       "      <td>0.002348</td>\n",
       "      <td>0.908082</td>\n",
       "      <td>0.913478</td>\n",
       "      <td>0.899392</td>\n",
       "      <td>0.915066</td>\n",
       "      <td>0.8993</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>[45000:49999]</td>\n",
       "      <td>9</td>\n",
       "      <td>45000</td>\n",
       "      <td>49999</td>\n",
       "      <td>2020-08-01 10:16:21</td>\n",
       "      <td>2020-08-11 19:42:35</td>\n",
       "      <td>reference</td>\n",
       "      <td>0.908585</td>\n",
       "      <td>0.002348</td>\n",
       "      <td>0.907402</td>\n",
       "      <td>0.915628</td>\n",
       "      <td>0.901542</td>\n",
       "      <td>0.915066</td>\n",
       "      <td>0.8993</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>[50000:54999]</td>\n",
       "      <td>10</td>\n",
       "      <td>50000</td>\n",
       "      <td>54999</td>\n",
       "      <td>2020-08-11 19:44:49</td>\n",
       "      <td>2020-08-22 02:52:23</td>\n",
       "      <td>reference</td>\n",
       "      <td>0.907106</td>\n",
       "      <td>0.002348</td>\n",
       "      <td>0.903066</td>\n",
       "      <td>0.914149</td>\n",
       "      <td>0.900063</td>\n",
       "      <td>0.915066</td>\n",
       "      <td>0.8993</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>[55000:59999]</td>\n",
       "      <td>11</td>\n",
       "      <td>55000</td>\n",
       "      <td>59999</td>\n",
       "      <td>2020-08-22 02:53:03</td>\n",
       "      <td>2020-09-01 03:03:23</td>\n",
       "      <td>reference</td>\n",
       "      <td>0.906334</td>\n",
       "      <td>0.002348</td>\n",
       "      <td>0.911346</td>\n",
       "      <td>0.913377</td>\n",
       "      <td>0.899290</td>\n",
       "      <td>0.915066</td>\n",
       "      <td>0.8993</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>[0:4999]</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4999</td>\n",
       "      <td>2020-09-01 03:10:01</td>\n",
       "      <td>2020-09-11 14:48:12</td>\n",
       "      <td>analysis</td>\n",
       "      <td>0.907264</td>\n",
       "      <td>0.002348</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.914307</td>\n",
       "      <td>0.900220</td>\n",
       "      <td>0.915066</td>\n",
       "      <td>0.8993</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>[5000:9999]</td>\n",
       "      <td>1</td>\n",
       "      <td>5000</td>\n",
       "      <td>9999</td>\n",
       "      <td>2020-09-11 14:53:29</td>\n",
       "      <td>2020-09-21 15:46:11</td>\n",
       "      <td>analysis</td>\n",
       "      <td>0.908891</td>\n",
       "      <td>0.002348</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.915935</td>\n",
       "      <td>0.901848</td>\n",
       "      <td>0.915066</td>\n",
       "      <td>0.8993</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>[10000:14999]</td>\n",
       "      <td>2</td>\n",
       "      <td>10000</td>\n",
       "      <td>14999</td>\n",
       "      <td>2020-09-21 15:46:29</td>\n",
       "      <td>2020-10-02 02:44:16</td>\n",
       "      <td>analysis</td>\n",
       "      <td>0.909456</td>\n",
       "      <td>0.002348</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.916499</td>\n",
       "      <td>0.902413</td>\n",
       "      <td>0.915066</td>\n",
       "      <td>0.8993</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>[15000:19999]</td>\n",
       "      <td>3</td>\n",
       "      <td>15000</td>\n",
       "      <td>19999</td>\n",
       "      <td>2020-10-02 02:45:52</td>\n",
       "      <td>2020-10-12 07:31:24</td>\n",
       "      <td>analysis</td>\n",
       "      <td>0.911442</td>\n",
       "      <td>0.002348</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.918485</td>\n",
       "      <td>0.904398</td>\n",
       "      <td>0.915066</td>\n",
       "      <td>0.8993</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>[20000:24999]</td>\n",
       "      <td>4</td>\n",
       "      <td>20000</td>\n",
       "      <td>24999</td>\n",
       "      <td>2020-10-12 07:31:43</td>\n",
       "      <td>2020-10-22 14:13:27</td>\n",
       "      <td>analysis</td>\n",
       "      <td>0.908264</td>\n",
       "      <td>0.002348</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.915307</td>\n",
       "      <td>0.901221</td>\n",
       "      <td>0.915066</td>\n",
       "      <td>0.8993</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>[25000:29999]</td>\n",
       "      <td>5</td>\n",
       "      <td>25000</td>\n",
       "      <td>29999</td>\n",
       "      <td>2020-10-22 14:21:04</td>\n",
       "      <td>2020-11-01 22:04:40</td>\n",
       "      <td>analysis</td>\n",
       "      <td>0.906829</td>\n",
       "      <td>0.002348</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.913872</td>\n",
       "      <td>0.899786</td>\n",
       "      <td>0.915066</td>\n",
       "      <td>0.8993</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>[30000:34999]</td>\n",
       "      <td>6</td>\n",
       "      <td>30000</td>\n",
       "      <td>34999</td>\n",
       "      <td>2020-11-01 22:04:59</td>\n",
       "      <td>2020-11-12 02:41:12</td>\n",
       "      <td>analysis</td>\n",
       "      <td>0.819675</td>\n",
       "      <td>0.002348</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.826718</td>\n",
       "      <td>0.812631</td>\n",
       "      <td>0.915066</td>\n",
       "      <td>0.8993</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>[35000:39999]</td>\n",
       "      <td>7</td>\n",
       "      <td>35000</td>\n",
       "      <td>39999</td>\n",
       "      <td>2020-11-12 02:42:07</td>\n",
       "      <td>2020-11-22 08:58:46</td>\n",
       "      <td>analysis</td>\n",
       "      <td>0.818623</td>\n",
       "      <td>0.002348</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.825666</td>\n",
       "      <td>0.811580</td>\n",
       "      <td>0.915066</td>\n",
       "      <td>0.8993</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>[40000:44999]</td>\n",
       "      <td>8</td>\n",
       "      <td>40000</td>\n",
       "      <td>44999</td>\n",
       "      <td>2020-11-22 08:59:10</td>\n",
       "      <td>2020-12-02 15:42:32</td>\n",
       "      <td>analysis</td>\n",
       "      <td>0.820996</td>\n",
       "      <td>0.002348</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.828039</td>\n",
       "      <td>0.813953</td>\n",
       "      <td>0.915066</td>\n",
       "      <td>0.8993</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>[45000:49999]</td>\n",
       "      <td>9</td>\n",
       "      <td>45000</td>\n",
       "      <td>49999</td>\n",
       "      <td>2020-12-02 15:49:34</td>\n",
       "      <td>2020-12-12 17:16:54</td>\n",
       "      <td>analysis</td>\n",
       "      <td>0.818481</td>\n",
       "      <td>0.002348</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.825525</td>\n",
       "      <td>0.811438</td>\n",
       "      <td>0.915066</td>\n",
       "      <td>0.8993</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>[50000:54999]</td>\n",
       "      <td>10</td>\n",
       "      <td>50000</td>\n",
       "      <td>54999</td>\n",
       "      <td>2020-12-12 17:22:06</td>\n",
       "      <td>2020-12-22 17:07:15</td>\n",
       "      <td>analysis</td>\n",
       "      <td>0.821284</td>\n",
       "      <td>0.002348</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.828327</td>\n",
       "      <td>0.814241</td>\n",
       "      <td>0.915066</td>\n",
       "      <td>0.8993</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>[55000:59999]</td>\n",
       "      <td>11</td>\n",
       "      <td>55000</td>\n",
       "      <td>59999</td>\n",
       "      <td>2020-12-22 17:08:38</td>\n",
       "      <td>2021-01-01 22:57:55</td>\n",
       "      <td>analysis</td>\n",
       "      <td>0.821463</td>\n",
       "      <td>0.002348</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.828506</td>\n",
       "      <td>0.814420</td>\n",
       "      <td>0.915066</td>\n",
       "      <td>0.8993</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            chunk                                                          \n",
       "              key chunk_index start_index end_index           start_date   \n",
       "0        [0:4999]           0           0      4999  2020-05-02 02:01:30  \\\n",
       "1     [5000:9999]           1        5000      9999  2020-05-12 13:14:18   \n",
       "2   [10000:14999]           2       10000     14999  2020-05-22 13:41:07   \n",
       "3   [15000:19999]           3       15000     19999  2020-06-01 18:59:40   \n",
       "4   [20000:24999]           4       20000     24999  2020-06-11 19:55:34   \n",
       "5   [25000:29999]           5       25000     29999  2020-06-21 20:51:22   \n",
       "6   [30000:34999]           6       30000     34999  2020-07-02 02:06:56   \n",
       "7   [35000:39999]           7       35000     39999  2020-07-12 05:35:07   \n",
       "8   [40000:44999]           8       40000     44999  2020-07-22 12:58:29   \n",
       "9   [45000:49999]           9       45000     49999  2020-08-01 10:16:21   \n",
       "10  [50000:54999]          10       50000     54999  2020-08-11 19:44:49   \n",
       "11  [55000:59999]          11       55000     59999  2020-08-22 02:53:03   \n",
       "12       [0:4999]           0           0      4999  2020-09-01 03:10:01   \n",
       "13    [5000:9999]           1        5000      9999  2020-09-11 14:53:29   \n",
       "14  [10000:14999]           2       10000     14999  2020-09-21 15:46:29   \n",
       "15  [15000:19999]           3       15000     19999  2020-10-02 02:45:52   \n",
       "16  [20000:24999]           4       20000     24999  2020-10-12 07:31:43   \n",
       "17  [25000:29999]           5       25000     29999  2020-10-22 14:21:04   \n",
       "18  [30000:34999]           6       30000     34999  2020-11-01 22:04:59   \n",
       "19  [35000:39999]           7       35000     39999  2020-11-12 02:42:07   \n",
       "20  [40000:44999]           8       40000     44999  2020-11-22 08:59:10   \n",
       "21  [45000:49999]           9       45000     49999  2020-12-02 15:49:34   \n",
       "22  [50000:54999]          10       50000     54999  2020-12-12 17:22:06   \n",
       "23  [55000:59999]          11       55000     59999  2020-12-22 17:08:38   \n",
       "\n",
       "                                     roc_auc                            \n",
       "               end_date     period     value sampling_error  realized   \n",
       "0   2020-05-12 13:12:37  reference  0.905532       0.002348  0.904142  \\\n",
       "1   2020-05-22 13:37:58  reference  0.909840       0.002348  0.907698   \n",
       "2   2020-06-01 18:55:46  reference  0.906800       0.002348  0.907093   \n",
       "3   2020-06-11 19:49:03  reference  0.906455       0.002348  0.909209   \n",
       "4   2020-06-21 20:51:08  reference  0.907449       0.002348  0.905651   \n",
       "5   2020-07-02 01:58:05  reference  0.908353       0.002348  0.910833   \n",
       "6   2020-07-12 05:34:14  reference  0.907318       0.002348  0.903115   \n",
       "7   2020-07-22 12:54:57  reference  0.908308       0.002348  0.908555   \n",
       "8   2020-08-01 10:14:52  reference  0.906435       0.002348  0.908082   \n",
       "9   2020-08-11 19:42:35  reference  0.908585       0.002348  0.907402   \n",
       "10  2020-08-22 02:52:23  reference  0.907106       0.002348  0.903066   \n",
       "11  2020-09-01 03:03:23  reference  0.906334       0.002348  0.911346   \n",
       "12  2020-09-11 14:48:12   analysis  0.907264       0.002348       NaN   \n",
       "13  2020-09-21 15:46:11   analysis  0.908891       0.002348       NaN   \n",
       "14  2020-10-02 02:44:16   analysis  0.909456       0.002348       NaN   \n",
       "15  2020-10-12 07:31:24   analysis  0.911442       0.002348       NaN   \n",
       "16  2020-10-22 14:13:27   analysis  0.908264       0.002348       NaN   \n",
       "17  2020-11-01 22:04:40   analysis  0.906829       0.002348       NaN   \n",
       "18  2020-11-12 02:41:12   analysis  0.819675       0.002348       NaN   \n",
       "19  2020-11-22 08:58:46   analysis  0.818623       0.002348       NaN   \n",
       "20  2020-12-02 15:42:32   analysis  0.820996       0.002348       NaN   \n",
       "21  2020-12-12 17:16:54   analysis  0.818481       0.002348       NaN   \n",
       "22  2020-12-22 17:07:15   analysis  0.821284       0.002348       NaN   \n",
       "23  2021-01-01 22:57:55   analysis  0.821463       0.002348       NaN   \n",
       "\n",
       "                                                                         \n",
       "   upper_confidence_boundary lower_confidence_boundary upper_threshold   \n",
       "0                   0.912575                  0.898488        0.915066  \\\n",
       "1                   0.916883                  0.902797        0.915066   \n",
       "2                   0.913844                  0.899757        0.915066   \n",
       "3                   0.913498                  0.899412        0.915066   \n",
       "4                   0.914492                  0.900405        0.915066   \n",
       "5                   0.915396                  0.901310        0.915066   \n",
       "6                   0.914361                  0.900275        0.915066   \n",
       "7                   0.915351                  0.901265        0.915066   \n",
       "8                   0.913478                  0.899392        0.915066   \n",
       "9                   0.915628                  0.901542        0.915066   \n",
       "10                  0.914149                  0.900063        0.915066   \n",
       "11                  0.913377                  0.899290        0.915066   \n",
       "12                  0.914307                  0.900220        0.915066   \n",
       "13                  0.915935                  0.901848        0.915066   \n",
       "14                  0.916499                  0.902413        0.915066   \n",
       "15                  0.918485                  0.904398        0.915066   \n",
       "16                  0.915307                  0.901221        0.915066   \n",
       "17                  0.913872                  0.899786        0.915066   \n",
       "18                  0.826718                  0.812631        0.915066   \n",
       "19                  0.825666                  0.811580        0.915066   \n",
       "20                  0.828039                  0.813953        0.915066   \n",
       "21                  0.825525                  0.811438        0.915066   \n",
       "22                  0.828327                  0.814241        0.915066   \n",
       "23                  0.828506                  0.814420        0.915066   \n",
       "\n",
       "                           \n",
       "   lower_threshold  alert  \n",
       "0           0.8993  False  \n",
       "1           0.8993  False  \n",
       "2           0.8993  False  \n",
       "3           0.8993  False  \n",
       "4           0.8993  False  \n",
       "5           0.8993  False  \n",
       "6           0.8993  False  \n",
       "7           0.8993  False  \n",
       "8           0.8993  False  \n",
       "9           0.8993  False  \n",
       "10          0.8993  False  \n",
       "11          0.8993  False  \n",
       "12          0.8993  False  \n",
       "13          0.8993  False  \n",
       "14          0.8993  False  \n",
       "15          0.8993  False  \n",
       "16          0.8993  False  \n",
       "17          0.8993  False  \n",
       "18          0.8993   True  \n",
       "19          0.8993   True  \n",
       "20          0.8993   True  \n",
       "21          0.8993   True  \n",
       "22          0.8993   True  \n",
       "23          0.8993   True  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results = pd.read_csv(transformer.output_path + \"/\" + inference_dataset.split(\"/\")[-1] + \".out\", header = [0,1])\n",
    "results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Clean-up"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### A. Delete the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:sagemaker:Deleting model with name: nannyml-performance-estimation-1350cd6b-2023-08-21-06-21-52-799\n"
     ]
    }
   ],
   "source": [
    "transformer.delete_model()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### B. Unsubscribe to the listing (optional)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you would like to unsubscribe to the algorithm, follow these steps. Before you cancel the subscription, ensure that you do not have any [deployable model](https://console.aws.amazon.com/sagemaker/home#/models) created from the model package or using the algorithm. Note - You can find this information by looking at the container name associated with the model. \n",
    "\n",
    "**Steps to unsubscribe to product from AWS Marketplace**:\n",
    "1. Navigate to __Machine Learning__ tab on [__Your Software subscriptions page__](https://aws.amazon.com/marketplace/ai/library?productType=ml&ref_=mlmp_gitdemo_indust)\n",
    "2. Locate the listing that you want to cancel the subscription for, and then choose __Cancel Subscription__  to cancel the subscription.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_python3",
   "language": "python",
   "name": "conda_python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
